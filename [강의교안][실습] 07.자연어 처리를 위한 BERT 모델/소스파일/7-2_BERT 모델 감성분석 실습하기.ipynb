{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_2_BERT_IMDB",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "cyoXh9C9rpRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "k-A_IyXgrqNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/mnt')"
      ],
      "metadata": {
        "id": "5cb_Y_bnrrDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"/content/mnt/MyDrive/data/IMDB Dataset.csv\", encoding='cp949')"
      ],
      "metadata": {
        "id": "QiDCY4DdrsLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "86s3U444rthf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_idx, test_idx,_ ,_ = train_test_split(dataset.index, dataset.sentiment, \n",
        "                                            test_size=0.2, stratify=dataset.sentiment)\n",
        "train_set = dataset.iloc[train_idx]\n",
        "test_set = dataset.iloc[test_idx]\n",
        "train_set.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "u2pc1s9bruWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx, valid_idx, _, _ = train_test_split(train_set.index, train_set.sentiment, \n",
        "                                              test_size=0.3, stratify=train_set.sentiment)\n",
        "valid_set = train_set.iloc[valid_idx]\n",
        "train_set = train_set.iloc[train_idx]"
      ],
      "metadata": {
        "id": "BUj6IrgFrvao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.shape, valid_set.shape, test_set.shape"
      ],
      "metadata": {
        "id": "TsLYMo5Lrwrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class BertDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, reviews, sentiments, tokenizer):\n",
        "        self.reviews    = reviews\n",
        "        self.sentiments = sentiments\n",
        "        self.tokenizer  = tokenizer\n",
        "        self.max_len    = tokenizer.model_max_length\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        review = str(self.reviews[index])\n",
        "        sentiments = self.sentiments[index]\n",
        "\n",
        "        encoded_review = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            add_special_tokens    = True,\n",
        "            max_length            = self.max_len,\n",
        "            return_token_type_ids = False,\n",
        "            return_attention_mask = True,\n",
        "            return_tensors        = \"pt\",\n",
        "            padding               = \"max_length\",\n",
        "            truncation            = True\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoded_review['input_ids'][0],\n",
        "            'attention_mask': encoded_review['attention_mask'][0],\n",
        "            'labels': torch.tensor(sentiments, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "xNZ4_UWHrxxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "bert_token_model = 'bert-base-uncased'\n",
        "bert_model_name = bert_token_model #'bert-large-uncased'\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(bert_token_model)"
      ],
      "metadata": {
        "id": "XmSOM1Qbrz6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_dataset = BertDataset(\n",
        "    reviews    = train_set.review.tolist(),\n",
        "    sentiments = train_set.sentiment.tolist(),\n",
        "    tokenizer  = tokenizer,\n",
        ")\n",
        "\n",
        "valid_set_dataset = BertDataset(\n",
        "    reviews    = valid_set.review.tolist(),\n",
        "    sentiments = valid_set.sentiment.tolist(),\n",
        "    tokenizer  = tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "524zGMhNr0-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(bert_model_name)"
      ],
      "metadata": {
        "id": "fLszfQV8r2fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_strategy = 3\n",
        "\n",
        "if tl_strategy == 1:\n",
        "  for name, param in model.bert.named_parameters():\n",
        "    print(name)\n",
        "    param.requires_grad = False\n",
        "\n",
        "elif tl_strategy == 2:\n",
        "  for name, param in model.bert.named_parameters():\n",
        "    if not name.startswith('pooler'):\n",
        "      param.requires_grad = False\n",
        "\n",
        "elif tl_strategy == 3:\n",
        "  for name, param in model.bert.named_parameters():\n",
        "    if ( not name.startswith('pooler') ) and \"layer.23\" not in name :\n",
        "      param.requires_grad = False"
      ],
      "metadata": {
        "id": "CY81ff4ur3bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "model_dir = './model'\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'accuracy': acc}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir                  = model_dir,\n",
        "    num_train_epochs            = 1,\n",
        "    per_device_train_batch_size = 128,\n",
        "    per_device_eval_batch_size  = 64,\n",
        "    warmup_steps                = 500,\n",
        "    weight_decay                = 0.01,\n",
        "    save_strategy               = \"epoch\",\n",
        "    evaluation_strategy         = \"steps\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    train_dataset   = train_set_dataset,\n",
        "    eval_dataset    = valid_set_dataset,\n",
        "    compute_metrics = compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Bi-0R1r0r5IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_dataset = BertDataset(\n",
        "    reviews    = test_set.review.tolist(),\n",
        "    sentiments = test_set.sentiment.tolist(),\n",
        "    tokenizer  = tokenizer,\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./model\",\n",
        "    do_predict = True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    compute_metrics = compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.predict(test_set_dataset)"
      ],
      "metadata": {
        "id": "anWNhwugr66i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}